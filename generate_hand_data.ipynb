{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_hand_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntKwuK9JLOTc",
        "outputId": "cb03dab2-4ca1-4aaf-d2c9-af71ffab8678"
      },
      "source": [
        "# mounting drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCoU87jJLSgH",
        "outputId": "8c431db1-2435-46b3-ab05-8dd213529c6b"
      },
      "source": [
        "cd /content/drive/MyDrive/COS429_Final_Project/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1ovw9re0A-fNM5W9dPWViPUskeUdZQ7j6/COS429_Final_Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msz5jdMiLY0F"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsSCpY2lLdQl"
      },
      "source": [
        "# HOW TO USE: If you have a folder with classes and image frames in those classes and want to create a train/val split\n",
        "\n",
        "# new data folder name to contain train/val split folders\n",
        "new_folder_name = 'BOSTON_DATA_28_HANDS_TRAINVAL_V2' # folder name to create train val and put the folders in there\n",
        "dest = new_folder_name\n",
        "source = \"BOSTON_DATA_28_TRAINVAL\" # where the frames are atm (not in train/val split)\n",
        "train_test_split = 0.3\n",
        "anno_folder = \"BOSTON_DATA_28_ANNOHANDS_TRAINVAL_V2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVDvYhahTXgv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f2977ee-a26c-4e87-863a-543e341fee1f"
      },
      "source": [
        "label_names = os.listdir(source+'/train')\n",
        "\n",
        "class_name = {}\n",
        "for i, label in enumerate(label_names):\n",
        "  class_name[label] = i"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"label_names = os.listdir(source+'/train')\\n\\nclass_name = {}\\nfor i, label in enumerate(label_names):\\n  class_name[label] = i\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "dzh5x5BiMt7E",
        "outputId": "eda8437a-7781-4f11-f6a8-6b5525d31489"
      },
      "source": [
        "\n",
        "os.system('mkdir '+ new_folder_name)\n",
        "os.system('mkdir '+ new_folder_name+'/train')\n",
        "os.system('mkdir '+ new_folder_name+'/val')\n",
        "\n",
        "os.system('mkdir '+ anno_folder)\n",
        "os.system('mkdir '+ anno_folder+'/train')\n",
        "os.system('mkdir '+ anno_folder+'/val')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nos.system('mkdir '+ new_folder_name)\\nos.system('mkdir '+ new_folder_name+'/train')\\nos.system('mkdir '+ new_folder_name+'/val')\\n\\nos.system('mkdir '+ anno_folder)\\nos.system('mkdir '+ anno_folder+'/train')\\nos.system('mkdir '+ anno_folder+'/val')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIvjgKkJ8kNq",
        "outputId": "64eb7427-fd08-4974-dfc1-0e78b89b31de"
      },
      "source": [
        "# Minimum dependency for MediaPipe Solutions Python API is opencv-python\n",
        "!pip install opencv-python~=3.4.11\n",
        "!pip install mediapipe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python~=3.4.11 in /usr/local/lib/python3.6/dist-packages (3.4.11.45)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python~=3.4.11) (1.18.5)\n",
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mediapipe) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from mediapipe) (1.15.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from mediapipe) (0.8)\n",
            "Requirement already satisfied: opencv-python<4.0.0,>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from mediapipe) (3.4.11.45)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from mediapipe) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.6/dist-packages (from mediapipe) (3.12.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from mediapipe) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.11.4->mediapipe) (50.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXZW7mSQAnie"
      },
      "source": [
        "import math\n",
        "from typing import List, Tuple, Union\n",
        "\n",
        "import cv2\n",
        "import dataclasses\n",
        "import numpy as np\n",
        "\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "\n",
        "RGB_CHANNELS = 3\n",
        "RED_COLOR = (0, 0, 255)\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class DrawingSpec:\n",
        "  # Color for drawing the annotation. Default to the green color.\n",
        "  color: Tuple[int, int, int] = (0, 255, 0)\n",
        "  # Thickness for drawing the annotation. Default to 2 pixels.\n",
        "  thickness: int = 2\n",
        "  # Circle radius. Default to 2 pixels.\n",
        "  circle_radius: int = 2\n",
        "\n",
        "\n",
        "def _normalized_to_pixel_coordinates(\n",
        "    normalized_x: float, normalized_y: float, image_width: int,\n",
        "    image_height: int) -> Union[None, Tuple[int, int]]:\n",
        "  \"\"\"Converts normalized value pair to pixel coordinates.\"\"\"\n",
        "\n",
        "  # Checks if the float value is between 0 and 1.\n",
        "  def is_valid_normalized_value(value: float) -> bool:\n",
        "    return (value > 0 or math.isclose(0, value)) and (value < 1 or\n",
        "                                                      math.isclose(1, value))\n",
        "\n",
        "  if not (is_valid_normalized_value(normalized_x) and\n",
        "          is_valid_normalized_value(normalized_y)):\n",
        "    # TODO: Draw coordinates even if it's outside of the image bounds.\n",
        "    return None\n",
        "  x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
        "  y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
        "  return x_px, y_px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC-O3haC8s7K"
      },
      "source": [
        "# For static images:\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(\n",
        "    static_image_mode=True,\n",
        "    max_num_hands=2,\n",
        "    min_detection_confidence=0.05)\n",
        "\n",
        "from google.protobuf.json_format import MessageToDict\n",
        "\n",
        "def vconcat_resize_min(im_list, interpolation=cv2.INTER_CUBIC):\n",
        "    w_min = min(im.shape[1] for im in im_list)\n",
        "    im_list_resize = [cv2.resize(im, (w_min, int(im.shape[0] * w_min / im.shape[1])), interpolation=interpolation)\n",
        "                      for im in im_list]\n",
        "    return cv2.vconcat(im_list_resize)\n",
        "\n",
        "def get_crop_info(left, right, top, bottom, padding, image_rows, image_cols):\n",
        "  if left-padding < 0:\n",
        "    left = 0\n",
        "  else:\n",
        "    left = left-padding\n",
        "\n",
        "  if top-padding < 0:\n",
        "    top = 0\n",
        "  else:\n",
        "    top = top-padding\n",
        "\n",
        "  if right+padding > image_rows:\n",
        "    right = image_rows\n",
        "  else:\n",
        "    right = right+padding\n",
        "\n",
        "  if bottom+padding > image_cols:\n",
        "    bottom = image_cols\n",
        "  else:\n",
        "    bottom = bottom+padding\n",
        "  \n",
        "  y = min(int(top), int(bottom))\n",
        "  h = int(abs(top-bottom))\n",
        "\n",
        "  x = min(int(left), int(right))\n",
        "  w = int(abs(left-right))\n",
        "  return x, y, w, h\n",
        "\n",
        "def get_crop_img(image, x, y, w, h):\n",
        "  crop_img = image[int(y):int(y+h), int(x):int(x+w)]\n",
        "  return crop_img\n",
        "\n",
        "def extract_hand(file_name, image_write_path, anno_image_write_path, padding=50):\n",
        "  # Read an image, flip it around y-axis for correct handedness output (see\n",
        "  # above).\n",
        "  image = cv2.flip(cv2.imread(file_name), 1)\n",
        "  # Convert the BGR image to RGB before processing.\n",
        "  # results = hands.process(image)\n",
        "  hands = mp_hands.Hands(\n",
        "    static_image_mode=True,\n",
        "    max_num_hands=2,\n",
        "    min_detection_confidence=0.05)\n",
        "  results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  x_0= []\n",
        "  y_0 = []\n",
        "\n",
        "  x_1= []\n",
        "  y_1 = []\n",
        "\n",
        "  idx_to_coordinates = {}\n",
        "  image_rows, image_cols, _ = image.shape\n",
        "\n",
        "  # Print handedness and draw hand landmarks on the image.\n",
        "  #print('handedness:', results.multi_handedness)\n",
        "  if not results.multi_hand_landmarks:\n",
        "    # write back the image image\n",
        "    cv2.imwrite(image_write_path, image)\n",
        "    #cv2.imwrite(anno_image_write_path, image)\n",
        "    return\n",
        "\n",
        "  #MessageToDict(hand_handedness)\n",
        "  #annotated_image_0 = image.copy() #right \n",
        "  #annotated_image_1 = image.copy() #left \n",
        "  hands = len(results.multi_hand_landmarks)\n",
        "  blank_image = np.zeros((image_rows,image_rows,3), np.uint8)\n",
        "\n",
        "  for i, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
        "    handedness = MessageToDict(results.multi_handedness[i])['classification'][0]['label']\n",
        "    for idx, landmark in enumerate(hand_landmarks.landmark):\n",
        "      landmark_px = _normalized_to_pixel_coordinates(landmark.x, landmark.y,\n",
        "                                                   image_cols, image_rows)\n",
        "      if landmark_px !=None:\n",
        "        if handedness=='Right':\n",
        "          x_0.append(landmark_px[0])\n",
        "        else:\n",
        "          x_1.append(landmark_px[0])\n",
        "\n",
        "        if handedness=='Right':\n",
        "          y_0.append(landmark_px[1])\n",
        "        else:\n",
        "          y_1.append(landmark_px[1])\n",
        "\n",
        "    '''if handedness=='Right':\n",
        "       mp_drawing.draw_landmarks(annotated_image_0, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
        "    if handedness=='Left':\n",
        "       mp_drawing.draw_landmarks(annotated_image_1, hand_landmarks, mp_hands.HAND_CONNECTIONS)'''\n",
        "    \n",
        "  if x_0 == []: # no right hand\n",
        "    crop_img0 = blank_image\n",
        "    #crop_anno_img0 = blank_image\n",
        "  else:\n",
        "    left0, right0, top0, bottom0 = min(x_0), max(x_0), min(y_0), max(y_0)\n",
        "    x0, y0, w0, h0= get_crop_info(left0, right0, top0, bottom0, padding, image_rows, image_cols)\n",
        "    w0 = max(w0, h0)\n",
        "    crop_img0 = get_crop_img(image, x0, y0, w0, w0)\n",
        "    #crop_anno_img0 = get_crop_img(annotated_image_0, x0, y0, w0, w0)\n",
        "\n",
        "  if x_1 == []: # no right hand\n",
        "    crop_img1 = blank_image\n",
        "    #crop_anno_img1 = blank_image\n",
        "  else:\n",
        "    left1, right1, top1, bottom1 = min(x_1), max(x_1), min(y_1), max(y_1)\n",
        "    x1, y1, w1, h1= get_crop_info(left1, right1, top1, bottom1, padding, image_rows, image_cols)\n",
        "    w1 = max(w1, h1)\n",
        "    crop_img1 = get_crop_img(image, x1, y1, w1, w1)\n",
        "    #crop_anno_img1 = get_crop_img(annotated_image_1, x1, y1, w1, w1)\n",
        "\n",
        "\n",
        "  if x_1 == [] and x_0==[]:\n",
        "    hand = image\n",
        "    #hand_anno = image\n",
        "  else:\n",
        "    hand = vconcat_resize_min([crop_img0, crop_img1])\n",
        "    #hand_anno = vconcat_resize_min([crop_anno_img0, crop_anno_img1])\n",
        "\n",
        "  cv2.imwrite(image_write_path, cv2.flip(hand, 1))\n",
        "  #cv2.imwrite(anno_image_write_path, cv2.flip(hand_anno, 1))\n",
        "  return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M0OlzR0ARzK"
      },
      "source": [
        "#extract_hand('/content/13855-0.jpg', '/content/img_hand_new.png', '/content/anno_img_hand_new.png', padding=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkMA369C6sz9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "a99ea0d0-2397-44f5-de33-4e05e9e4e92f"
      },
      "source": [
        "train_path= '/content/drive/MyDrive/COS429_Final_Project/'+ source+ '/train/'\n",
        "\n",
        "for c_name in class_name.keys():\n",
        "  #os.system('mkdir '+ '/content/drive/MyDrive/COS429_Final_Project/'+ anno_folder + '/train/' + c_name)\n",
        "  os.system('mkdir '+ '/content/drive/MyDrive/COS429_Final_Project/'+ new_folder_name + '/train/' + c_name)\n",
        "  print(c_name)\n",
        "  for folder_name in os.listdir(train_path+c_name):\n",
        "    #os.system('mkdir '+ '/content/drive/MyDrive/COS429_Final_Project/'+ anno_folder + '/train/' + c_name+ '/'+folder_name)\n",
        "    os.system('mkdir '+ '/content/drive/MyDrive/COS429_Final_Project/'+ new_folder_name + '/train/' + c_name+ '/'+folder_name)\n",
        "\n",
        "    folder_path = '/content/drive/MyDrive/COS429_Final_Project/'+ source+ '/train/' + c_name+ '/'+folder_name\n",
        "    print(folder_name)\n",
        "    for image_name in os.listdir(folder_path):\n",
        "      image_write_path = '/content/drive/MyDrive/COS429_Final_Project/'+ new_folder_name+ '/train/' + c_name+ '/'+folder_name+'/'+image_name\n",
        "      anno_image_write_path = '/content/drive/MyDrive/COS429_Final_Project/'+ anno_folder+ '/train/' + c_name+ '/'+folder_name+'/'+image_name\n",
        "      image_path = '/content/drive/MyDrive/COS429_Final_Project/'+ source + '/train/' + c_name+ '/'+folder_name+'/'+image_name\n",
        "      extract_hand(image_path, image_write_path, anno_image_write_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"train_path= '/content/drive/MyDrive/COS429_Final_Project/'+ source+ '/train/'\\n\\nfor c_name in class_name.keys():\\n  #os.system('mkdir '+ '/content/drive/MyDrive/COS429_Final_Project/'+ anno_folder + '/train/' + c_name)\\n  os.system('mkdir '+ '/content/drive/MyDrive/COS429_Final_Project/'+ new_folder_name + '/train/' + c_name)\\n  print(c_name)\\n  for folder_name in os.listdir(train_path+c_name):\\n    #os.system('mkdir '+ '/content/drive/MyDrive/COS429_Final_Project/'+ anno_folder + '/train/' + c_name+ '/'+folder_name)\\n    os.system('mkdir '+ '/content/drive/MyDrive/COS429_Final_Project/'+ new_folder_name + '/train/' + c_name+ '/'+folder_name)\\n\\n    folder_path = '/content/drive/MyDrive/COS429_Final_Project/'+ source+ '/train/' + c_name+ '/'+folder_name\\n    print(folder_name)\\n    for image_name in os.listdir(folder_path):\\n      image_write_path = '/content/drive/MyDrive/COS429_Final_Project/'+ new_folder_name+ '/train/' + c_name+ '/'+folder_name+'/'+image_name\\n      anno_image_write_path = '/content/drive/MyDrive/COS429_Final_Project/'+ anno_folder+ '/train/' + c_name+ '/'+folder_name+'/'+image_name\\n      image_path = '/content/drive/MyDrive/COS429_Final_Project/'+ source + '/train/' + c_name+ '/'+folder_name+'/'+image_name\\n      extract_hand(image_path, image_write_path, anno_image_write_path)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT4gYoJ8BmDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c0eae3a-86e4-4b84-abca-1305528e4a85"
      },
      "source": [
        "val_path= '/content/drive/MyDrive/COS429_Final_Project/'+ source+ '/val/'\n",
        "\n",
        "for c_name in class_name.keys():\n",
        "  os.system('mkdir '+ '/content/drive/MyDrive/COS429_Final_Project/'+ anno_folder + '/val/' + c_name)\n",
        "  os.system('mkdir '+ '/content/drive/MyDrive/COS429_Final_Project/'+ new_folder_name + '/val/' + c_name)\n",
        "  print(c_name)\n",
        "  for folder_name in os.listdir(val_path+c_name):\n",
        "    os.system('mkdir '+ '/content/drive/MyDrive/COS429_Final_Project/'+ anno_folder + '/val/' + c_name+ '/'+folder_name)\n",
        "    os.system('mkdir '+ '/content/drive/MyDrive/COS429_Final_Project/'+ new_folder_name + '/val/' + c_name+ '/'+folder_name)\n",
        "\n",
        "    folder_path = '/content/drive/MyDrive/COS429_Final_Project/'+ source+ '/val/' + c_name+ '/'+folder_name\n",
        "    print(folder_name)\n",
        "    for image_name in os.listdir(folder_path):\n",
        "      image_write_path = '/content/drive/MyDrive/COS429_Final_Project/'+ new_folder_name+ '/val/' + c_name+ '/'+folder_name+'/'+image_name\n",
        "      anno_image_write_path = '/content/drive/MyDrive/COS429_Final_Project/'+ anno_folder+ '/val/' + c_name+ '/'+folder_name+'/'+image_name\n",
        "      image_path = '/content/drive/MyDrive/COS429_Final_Project/'+ source + '/val/' + c_name+ '/'+folder_name+'/'+image_name\n",
        "      extract_hand(image_path, image_write_path, anno_image_write_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CRASH\n",
            "302933\n",
            "305575\n",
            "305211\n",
            "FAVORITE\n",
            "263488\n",
            "51850\n",
            "51875\n",
            "299658\n",
            "301352\n",
            "307281\n",
            "FRIEND\n",
            "13577\n",
            "13862\n",
            "301376\n",
            "300678\n",
            "13794\n",
            "300650\n",
            "301214\n",
            "300916\n",
            "299707\n",
            "263791\n",
            "302790\n",
            "299168\n",
            "299505\n",
            "300939\n",
            "300976\n",
            "300792\n",
            "14529\n",
            "203474\n",
            "13545\n",
            "13928\n",
            "48267\n",
            "203334\n",
            "203422\n",
            "203430\n",
            "203573\n",
            "203641\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}